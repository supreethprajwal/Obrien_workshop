{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial steps\n",
    "1. Go to https://jupyter.org/try\n",
    "2. Click on 'Try JupyterLab'\n",
    "3. Once JupyterLab environment is created: File -> New -> Terminal\n",
    "4. In the terminal, type following commands\n",
    "        git clone https://github.com/supreethprajwal/Obrien_workshop.git\n",
    "5. A folder by the name 'Obrien_workshop' should appear in the file directory\n",
    "6. Double click on the folder 'Obrien_workshop'\n",
    "7. Double click on 'sepsisPrediction_v1.ipynb' to open the jupyter notebook\n",
    "\n",
    "### Physionet Challenge 2019 website\n",
    "1. https://physionet.org/content/challenge-2019/1.0.0/\n",
    "\n",
    "### Downloading data\n",
    "1. In the terminal, type following commands\n",
    "        cd Obrien_workshop/\n",
    "        wget https://archive.physionet.org/users/shared/challenge-2019/training_setB.zip\n",
    "        unzip training_setB.zip      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for loading physionet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a\n",
    "def load_challenge_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip()\n",
    "        column_names = header.split('|')\n",
    "        data = np.loadtxt(f, delimiter='|')\n",
    "\n",
    "    # Ignore SepsisLabel column if present.\n",
    "    if column_names[-1] == 'SepsisLabel':\n",
    "        column_names = column_names[:-1]\n",
    "        labels = data[:, -1]\n",
    "        data = data[:, :-1]\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "1. Load the list of files in the input directory\n",
    "2. Split the records to training and testing set\n",
    "3. Convert the data into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the input directory\n",
    "input_directory = 'training_setB'\n",
    "\n",
    "# Find files.\n",
    "files = []\n",
    "for f in os.listdir(input_directory):\n",
    "    if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('psv'):\n",
    "        files.append(f)\n",
    "\n",
    "# Total number of files in the input directory\n",
    "num_files = len(files)\n",
    "\n",
    "# SPlit the files into training and testing set\n",
    "# 80% of data -> Training\n",
    "# 20% of data -> Testing\n",
    "shuffled_indices = np.random.permutation(num_files)\n",
    "train_indices = shuffled_indices[0:int(np.round(0.8*num_files))]\n",
    "test_indices = shuffled_indices[int(np.round(0.8*num_files)):]\n",
    "\n",
    "train_files = [] # List of files containing training data\n",
    "test_files = [] # List of files containing testing data\n",
    "for i in range(train_indices.shape[0]):\n",
    "    train_files.append(files[train_indices[i]])\n",
    "    \n",
    "for i in range(test_indices.shape[0]):\n",
    "    test_files.append(files[test_indices[i]])\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "    \n",
    "for i, f in enumerate(train_files):\n",
    "    # Load data.\n",
    "    input_file = os.path.join(input_directory, f)\n",
    "    data_patient, label_patient = load_challenge_data(input_file)\n",
    "    train_data.append(data_patient)\n",
    "    train_labels.append(label_patient)\n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "    \n",
    "for i, f in enumerate(test_files):\n",
    "    # Load data.\n",
    "    input_file = os.path.join(input_directory, f)\n",
    "    data_patient, label_patient = load_challenge_data(input_file)\n",
    "    test_data.append(data_patient)\n",
    "    test_labels.append(label_patient)\n",
    "\n",
    "test_data = np.concatenate(test_data)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization of data\n",
    "1. Compute the mean and standard deviation of ONLY training set\n",
    "2. Use the statistics computed to standardize Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.nanmean(train_data, axis = 0)\n",
    "x_std = np.nanstd(train_data, axis = 0)\n",
    "\n",
    "# For Nan entries, replace with 0\n",
    "# For the remaining entries, standardize with mean and std\n",
    "train_data = np.nan_to_num((train_data - x_mean) / x_std)\n",
    "test_data = np.nan_to_num((test_data - x_mean) / x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "1. We will use a simple Multinomial logistic regression model to model the data\n",
    "\n",
    "### Exercise\n",
    "1. Use a different penalty for Logistic Regression (LR) and plot the AUC curves\n",
    "2. Use a Support Vector Machine classifier instead of LR and plot the AUC curves\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "3. Use a Random Forest Classifier instead of LR and plot the AUC curves \n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "4. Build a 2 layer Neural network and plot the AUC curves\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty = 'l2', random_state=0, solver='lbfgs', max_iter = 150,\n",
    "                           multi_class='multinomial').fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code for training 2 layer Neural Network\n",
    "# Uncomment the below lines to execute the code\n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "#model = MLPClassifier(hidden_layer_sizes=(10,5), activation='relu', solver='adam', max_iter = 150, alpha=0.0001,\n",
    "#                     learning_rate_init=0.001, batch_size='auto').fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction\n",
    "1. Use the trained model to get output probability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_score = model.predict_proba(train_data)\n",
    "test_pred_score = model.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "1. Compute Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Compute AUC of training set\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n",
    "fpr_train, tpr_train, _ = metrics.roc_curve(train_labels, train_pred_score[:,1], pos_label = 1)\n",
    "train_auc = metrics.auc(fpr_train, tpr_train)\n",
    "\n",
    "# Compute AUC of testing set\n",
    "fpr_test, tpr_test, _ = metrics.roc_curve(test_labels, test_pred_score[:,1], pos_label = 1)\n",
    "test_auc = metrics.auc(fpr_test, tpr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AUC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training AUC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_train, tpr_train, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % train_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for training data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Testing AUC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr_test, tpr_test, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % test_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for testing data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
